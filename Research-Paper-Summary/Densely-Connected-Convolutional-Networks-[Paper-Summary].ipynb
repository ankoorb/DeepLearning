{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densely Connected Convolutional Networks\n",
    "- **Authors:** Gao Huang et al.\n",
    "- **[ArXiv Link](https://arxiv.org/pdf/1608.06993.pdf)** \n",
    "\n",
    "---\n",
    "- Introduced Dense Convolutional Network (DenseNet) which connects each layer to every other layer in a feed-forward fashion, this enables maximum information flow between layers in the network.\n",
    "- DenseNet Advantages\n",
    "    - Alleviate vanishing gradient problem \n",
    "    - Strengthen feature propagation\n",
    "    - Encourage feature reuse\n",
    "    - Reduce the number of parameters\n",
    "- Traditional CNN's with $L$ layers have $L$ connections (one between each layer and its subsequent layer) and DenseNet has $\\frac{L(L+1)}{2}$ direct connections\n",
    "- Concatenating feature maps learned by different layers increases variation in the input of subsequent layers and improves efficiency.\n",
    "---\n",
    "- Consider a single image $\\mathbf{x_{0}}$ that is passed through a CNN\n",
    "- $\\mathbf{x_{0}} \\rightarrow$ Input image\n",
    "- $L \\rightarrow$ # of Layers in the network\n",
    "- $H_{\\ell}(\\cdot) \\rightarrow$ A non-linear transformation implemented by layer $\\ell$. Non-linear transformation can be a composite function of operations such as Batch Normalization, ReLU, Pooling, or Convolution. `NOTE - Composite function used: [BN - ReLU - Conv(3x3)]`\n",
    "- $\\mathbf{x_{\\ell}} \\rightarrow$ Output of the $\\ell^{th}$ layer\n",
    "![](images/dense-block-details.png)\n",
    "- **Layer Connectivity**\n",
    "    - Traditional CNNs: $\\mathbf{x_{\\ell}} = H_{\\ell}(\\mathbf{x_{\\ell-1}})$\n",
    "    - ResNet - Adds a skip-connection that bypasses non-linear transformations with an identity function: $\\mathbf{x_{\\ell}} = H_{\\ell}(\\mathbf{x_{\\ell-1}}) + \\mathbf{x_{\\ell-1}}$ \n",
    "    - <font color=steelblue>DenseNet - The $\\ell^{th}$ layer receives the feature maps of all preceding layers $\\mathbf{x_{0}}, \\mathbf{x_{1}}, \\ldots, \\mathbf{x_{\\ell-1}}$ as input: $\\mathbf{x_{\\ell}} = H_{\\ell}([\\mathbf{x_{0}}, \\mathbf{x_{1}}, \\ldots, \\mathbf{x_{\\ell-1}}])$, where $[\\mathbf{x_{0}}, \\mathbf{x_{1}}, \\ldots, \\mathbf{x_{\\ell-1}}]$ is concatenation of the feature maps produced in layers $0, 1, \\ldots, \\ell-1$</font>\n",
    "- **Pooling Layers** - Essential part of CNN that changes the size of feature mapt\n",
    "    - Concatenation operation is not possible when size of feature map changes: To facilitate pooling network is divided into multiple densely connected **`dense blocks`**\n",
    "    - Layers between two adjacent **`dense blocks`** are referred to as **`transition layers`**. They change feature map sizes via convolution and pooling. `NOTE: Transition layer used: [BN - Conv(1x1) - Pool(2x2)]`\n",
    "    ![](images/densenet-full.png)\n",
    "- **Growth Rate $(k)$**\n",
    "    - Growth Rate $(k)$ is a hyper-parameter\n",
    "    - $k_{0} \\rightarrow$ # of channels in the input image\n",
    "    - Suppose each $H_{\\ell}(\\cdot)$ produces $k$ feature maps as output, this suggests that $\\ell^{th}$ layer has $k\\times(\\ell-1) + k_0$ feature map inputs\n",
    "- **Bottleneck Layers**\n",
    "    - Used 1x1 convolution as bottleneck layer before each 3x3 convolution to reduce the number of input feature maps, and thus to improve computational efficiency\n",
    "    - *Each 1x1 convolution reduces the input to $4k$ feature maps*\n",
    "    - Network with bottleneck layer: `DenseNet-B`\n",
    "- **Compression**\n",
    "    - To improve model compactness authors reduced number of feature maps at transition layers.\n",
    "    - If a dense block contains $m$ feature maps, the following transition layer was enabled to generate $\\lfloor \\theta m \\rfloor$ output feature maps, where $0 < \\theta \\leq 1$ and $\\theta \\rightarrow$ Compression factor. When $\\theta = 1$, the number of feature maps across transition layer remains unchanged\n",
    "    - Used $\\theta = 0.5$ for experiment\n",
    "    - DenseNet with compression: `DenseNet-C` and DenseNet with bottleneck and compression: `DenseNet-BC`\n",
    "\n",
    "---\n",
    "\n",
    "**DenseNet-BC (ImageNet)** `NOTE: Check paper for CIFAR and SVHN implementation details`\n",
    "![](images/densenet-table.png)\n",
    "- `conv` layer shown in the table corresponds the sequence `BN-ReLU-Conv`\n",
    "- 4 Dense Blocks\n",
    "- Input size: 224x224 with initial $2k$ convolutions with 7x7 filters with stride 2\n",
    "- Data augmentation same as ResNet\n",
    "- Training:\n",
    "    - Weight decay: $10^{-4}$\n",
    "    - Weight initialization: As discussed in paper [Delving Deep into Rectifiers:\n",
    "Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/pdf/1502.01852.pdf) - \"Microsoft Research Asia\" (MSRA) weight initialization. It is similar to `Xavier` initialization except it is designed for ReLU instead of TanH activation. In this method weights are initialized with a zero-mean Gaussian distribution whose standard deviation is $\\sqrt{\\frac{2}{n_l}}$, where $n_l = k^{2}_{l}d_{l-1}$, $k_l \\rightarrow$ Spatial filter size in layer $l$; $d_{l-1} \\rightarrow$ Number of filters in layer $l-1$\n",
    "    - Nestrov Momentum of 0.9 without dampening\n",
    "    - Train model for 90 epochs with mini-batch size: 256, learning rate: 0.1 set initially and lowered by a factor of 10 after epoch 30 and epoch 60. `NOTE: Because of GPU memory constraints, largest model (DenseNet-161) is trained with a mini-batch size 128. To compensate for the smaller batch size, model was trained for 100 epochs, and the learning rate was divided by 10 after epoch 90`\n",
    "\n",
    "---\n",
    "\n",
    "**DenseNet-BC-121 ($k=32$): Up to First Transition Layer** (NOTE: `Conv` correspond to `BN-ReLU-Conv`)\n",
    "\n",
    "- **Initial**\n",
    "    - $224 \\times 224 \\times 3 \\rightarrow$ Conv(7x7, s:2, p:3, c: $2k$) $\\rightarrow BN-ReLU$ $\\rightarrow 112 \\times 112 \\times 64 $\n",
    "    - $112 \\times 112 \\times 64 \\rightarrow$ Pool.Max(3x3, s:2, p:1) $\\rightarrow 56 \\times 56 \\times 64 $\n",
    "---\n",
    "- **DenseBlock-1**\n",
    "    - $56 \\times 56 \\times 64 \\rightarrow$ Conv(1x1, s:1, p:0, c: $4k$) $\\rightarrow 56 \\times 56 \\times 128 \\rightarrow$ Conv(3x3, s:1, p:1, c: $k$) $\\rightarrow 56 \\times 56 \\times 32 $\n",
    "    - $56 \\times 56 \\times [64+32] \\rightarrow$ Conv(1x1, s:1, p:0, c: $4k$) $\\rightarrow 56 \\times 56 \\times 128 \\rightarrow$ Conv(3x3, s:1, p:1, c: $k$) $\\rightarrow 56 \\times 56 \\times 32 $\n",
    "    - $56 \\times 56 \\times [64+32+32] \\rightarrow$ Conv(1x1, s:1, p:0, c: $4k$) $\\rightarrow 56 \\times 56 \\times 128 \\rightarrow$ Conv(3x3, s:1, p:1, c: $k$) $\\rightarrow 56 \\times 56 \\times 32 $\n",
    "    - $56 \\times 56 \\times [64+32+32+32] \\rightarrow$ Conv(1x1, s:1, p:0, c: $4k$) $\\rightarrow 56 \\times 56 \\times 128 \\rightarrow$ Conv(3x3, s:1, p:1, c: $k$) $\\rightarrow 56 \\times 56 \\times 32 $\n",
    "    - $56 \\times 56 \\times [64+32+32+32+32] \\rightarrow$ Conv(1x1, s:1, p:0, c: $4k$) $\\rightarrow 56 \\times 56 \\times 128 \\rightarrow$ Conv(3x3, s:1, p:1, c: $k$) $\\rightarrow 56 \\times 56 \\times 32 $\n",
    "    - $56 \\times 56 \\times [64+32+32+32+32+32] \\rightarrow$ Conv(1x1, s:1, p:0, c: $4k$) $\\rightarrow 56 \\times 56 \\times 128 \\rightarrow$ Conv(3x3, s:1, p:1, c: $k$) $\\rightarrow 56 \\times 56 \\times 32 $\n",
    "---\n",
    "- **Transition-1**\n",
    "    - $\\ell=6$ and $compression=0.5$\n",
    "    - $56 \\times 56 \\times [64+32+32+32+32+32+32] \\rightarrow$ Conv(1x1, s:1, p:0, c: $(k\\times \\ell + k_0)\\times compression$) $\\rightarrow 56 \\times 56 \\times 128$\n",
    "    - $56 \\times 56 \\times 128 \\rightarrow$ Pool.Avg(2x2, s:2, p:0) $\\rightarrow 28 \\times 28 \\times 128$\n",
    "    ---\n",
    "- **DenseBlock-2 ...** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanishing Gradient Problem** \n",
    "- As the information about the input or gradient passes through many layers, it can vanish by the time it reaches the end (or beginning) of the network). Vanishing Gradient problem depends on the choice of activation function. Non-linear activation functions such as `sigmoid` or `tanh` squash their inputs into a very small range ([0, 1] or [-1, 1]), as a result even a large change in input will produce a small change in output which results in small gradient. The problem becomes worse when the network is deep.\n",
    "- Addressing Vanishing Gradient Problem\n",
    "    - Using ReLU Activation\n",
    "    - ResNet\n",
    "    - Highway Networks\n",
    "    - Stochastic Depth - It shortens ResNets by randomly dropping layers (because many layers contribute very little and can be dropped) during training to allow better information and gradient flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Computational Bottleneck Using: `CONV(1x1, s:1, p:0)`**\n",
    "\n",
    "1x1 convolutional layers are used as dimension reduction modules to remove computational bottlenecks as well as to increase non-linearity. For example, a feature map with size 100 x 100 x C channels on convolution with $k$ 1x1 filters would result in a feature map of size 100 x 100 x $k$.\n",
    "![](images/conv-1x1.png)\n",
    "\n",
    "---\n",
    "\n",
    "- Suppose a convolutional layer outputs a tensor (feature maps) of size ($N$, $F$, $H$, $W$), where $N$: Batch size; $F$: Number of convolutional filters; $H$ and $W$: Height and width of feature maps. Now if this output is fed into a convolution layer with $f$ 1x1 filters with zero padding and stride 1, then the output tensor will have size ($N$, $f$, $H$, $W$). Thus using 1x1 convolution layers changes dimensionality (number of filters).\n",
    "    - If $f > F \\rightarrow$ then dimensionality (number of filters) is increased\n",
    "    - If $f < F \\rightarrow$ then dimensionality (number of filters) is decreased\n",
    "    \n",
    "![](images/bottleneck-comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Convolutions** *(CS231 Assignment-2: My solution)*\n",
    "![](images/im2col.png)\n",
    "![](images/im2col-for-loop.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv_forward_naive(x, w, b, conv_param):\n",
    "    \"\"\"\n",
    "    A naive implementation of the forward pass for a convolutional layer.\n",
    "\n",
    "    The input consists of N data points, each with C channels, height H and width\n",
    "    W. We convolve each input with F different filters, where each filter spans\n",
    "    all C channels and has height HH and width HH.\n",
    "\n",
    "    Input:\n",
    "    - x: Input data of shape (N, C, H, W)\n",
    "    - w: Filter weights of shape (F, C, HH, WW)\n",
    "    - b: Biases, of shape (F,)\n",
    "    - conv_param: A dictionary with the following keys:\n",
    "    - 'stride': The number of pixels between adjacent receptive fields in the\n",
    "      horizontal and vertical directions.\n",
    "    - 'pad': The number of pixels that will be used to zero-pad the input.\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
    "    H' = 1 + (H + 2 * pad - HH) / stride\n",
    "    W' = 1 + (W + 2 * pad - WW) / stride\n",
    "    - cache: (x, w, b, conv_param)\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the convolutional forward pass.                           #\n",
    "    # Hint: you can use the function np.pad for padding.                        #\n",
    "    #############################################################################\n",
    "    N, C, H, W = x.shape\n",
    "    F, C, HH, WW = w.shape\n",
    "    stride = conv_param['stride']\n",
    "    pad = conv_param['pad']\n",
    "    \n",
    "    # Pad input\n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    H_out = 1 + (H + 2 * pad - HH) / stride\n",
    "    W_out = 1 + (W + 2 * pad - WW) / stride\n",
    "    \n",
    "    # Create 'out' array of output data shape filled with zeros\n",
    "    out = np.zeros((N, F, H_out, W_out))\n",
    "    \n",
    "    ##----- im2col implementation - CS231n: winter1516_lecture_11.pdf -----##\n",
    "    # Calculate new size = K * K * C\n",
    "    filter_new_size = HH * WW * C \n",
    "    \n",
    "    # Reshape Filter: New shape = # of Filters x (K * K * C)\n",
    "    filter_reshaped = np.reshape(w, (F, filter_new_size))\n",
    "    #print 'Filter Reshaped Size: ', filter_reshaped.shape\n",
    "    \n",
    "    # Convolution Steps\n",
    "    for i in range(H_out):\n",
    "        top = i * stride # Top index\n",
    "        bottom = top + HH # Bottom index = Top index + Filter Height\n",
    "        \n",
    "        for j in range(W_out):\n",
    "            left = j * stride # Left index\n",
    "            right = left + WW # Right index = Left index + Filter Width\n",
    "            \n",
    "            # Slice x_padded as per top to bottom range and left to right range \n",
    "            # NOTE: Resulting shape = N x C x K x K\n",
    "            x_slice = x_padded[:, :, top:bottom, left:right]\n",
    "            \n",
    "            # Reshape x_slice: New shape = (K * K * C) x N\n",
    "            x_slice_reshaped = np.reshape(x_slice, (filter_new_size, N))\n",
    "            #print 'X Slice Reshaped Size: ', x_slice_reshaped.shape\n",
    "            \n",
    "            # Calculate: [# of Filters x (K * K * C) . (K * K * C) x N] + b, i.e. y = w'x + b\n",
    "            temp_y = filter_reshaped.dot(x_slice_reshaped).T + b\n",
    "            # print 'Dot Product + Sum Shape: ', temp_y.shape\n",
    "            out[:, :, i, j] = temp_y\n",
    "    ##---------------------------------------------------------------------## \n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    cache = (x, w, b, conv_param)\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1, 20, 5, 5) with Stride: 1 and Padding: 0 returns out shape: (1, 1, 5, 5)\n",
      "Number of Parameters: 25\n",
      "Output Feature Map: \n",
      "[[[[ 0.612  0.613  0.614  0.615  0.616]\n",
      "   [ 0.618  0.619  0.62   0.621  0.622]\n",
      "   [ 0.624  0.625  0.626  0.627  0.628]\n",
      "   [ 0.63   0.631  0.632  0.633  0.634]\n",
      "   [ 0.636  0.637  0.638  0.639  0.64 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Test: Conv(1x1, s:1, p:0)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "x_shape = (1, 20, 5, 5)\n",
    "w_shape = (1, 20, 1, 1)\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=w.shape[0])\n",
    "conv_param = {'stride': stride, 'pad': padding}\n",
    "\n",
    "out, _ = conv_forward_naive(x, w, b, conv_param=conv_param)\n",
    "print 'X shape: {} with Stride: {} and Padding: {} returns out shape: {}'.format(x.shape, stride, padding, out.shape)\n",
    "print 'Number of Parameters: {}'.format(out.size)\n",
    "print 'Output Feature Map: \\n', out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bottleneck vs Normal Computation Time comparison\n",
    "def run_bottleneck(N, C, H, W, f1, s1, p1, f2, k2, s2, p2):\n",
    "    \"\"\"\n",
    "    Inputs: N, C, H, W, f1, s1, p1, f2, k2, s2, p2\n",
    "    \"\"\"\n",
    "    x_1_shape = (N, C, H, W)\n",
    "    w_1_shape = (f1, C, 1, 1)\n",
    "    x_1 = np.linspace(-0.1, 0.5, num=np.prod(x_1_shape)).reshape(x_1_shape)\n",
    "    w_1 = np.linspace(-0.2, 0.3, num=np.prod(w_1_shape)).reshape(w_1_shape)\n",
    "    b_1 = np.linspace(-0.1, 0.2, num=w_1.shape[0])\n",
    "\n",
    "    w_2_shape = (f2, f1, k2, k2)\n",
    "    w_2 = np.linspace(-0.2, 0.3, num=np.prod(w_2_shape)).reshape(w_2_shape)\n",
    "    b_2 = np.linspace(-0.1, 0.2, num=w_2.shape[0])\n",
    "\n",
    "    conv_param_1 = {'stride': s1, 'pad': p1}\n",
    "    conv_param_2 = {'stride': s2, 'pad': p2}\n",
    "    out, _ = conv_forward_naive(x_1, w_1, b_1, conv_param=conv_param_1)\n",
    "    out, _ = conv_forward_naive(out, w_2, b_2, conv_param=conv_param_2)\n",
    "    return out\n",
    "\n",
    "def run_normal(N, C, H, W, f1, k, s, p):\n",
    "    \"\"\"\n",
    "    Inputs: N, C, H, W, f1, k1, s1, p1\n",
    "    \"\"\"\n",
    "    x_1_shape = (N, C, H, W)\n",
    "    w_1_shape = (f1, C, k, k)\n",
    "    x_1 = np.linspace(-0.1, 0.5, num=np.prod(x_1_shape)).reshape(x_1_shape)\n",
    "    w_1 = np.linspace(-0.2, 0.3, num=np.prod(w_1_shape)).reshape(w_1_shape)\n",
    "    b_1 = np.linspace(-0.1, 0.2, num=w_1.shape[0])\n",
    "    conv_param_1 = {'stride': s, 'pad': p}\n",
    "    out, _ = conv_forward_naive(x_1, w_1, b_1, conv_param=conv_param_1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.05 s per loop\n"
     ]
    }
   ],
   "source": [
    "# Test Bottleneck: Input (256 depth) -> [Conv(1x1, s:1, p:0, 64 depth) -> Conv(3x3, s:1, p:1, 256 depth)]\n",
    "%timeit -n 100 run_bottleneck(1, 256, 96, 96, 64, 1, 0, 256, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.4 s per loop\n"
     ]
    }
   ],
   "source": [
    "# Test Normal: Input (256 depth) -> Conv(3x3, s:1, p:1, 256 depth)\n",
    "%timeit -n 100 run_normal(1, 256, 96, 96, 256, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
