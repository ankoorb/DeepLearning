{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "\n",
    "**Authors:** K. Simonyan, A. Zisserman  \n",
    "**Link:** https://arxiv.org/pdf/1409.1556.pdf  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- Investigated the effect of the convolutional network depth on its accuracy in the large-scale image recognition (`Used very small 3 x 3 filters`)\n",
    "- Architecture:\n",
    "    - ConvNet input: Fixed size 224 x 224 RGB image (Preprocessing: Subtracted the mean RGB, computed on the training set, from each pixel)\n",
    "    - Filter size: 3 x 3 (Used 1 x 1 in one configuration)\n",
    "    - Convolution Stride is fixed to 1 pixel\n",
    "    - Spatial Padding: 1 pixel to preserve spatial resolution after convolution \n",
    "    - Spatial Pooling: 5 max pooling layers which follow some of the  convolution layers. Max pooling is performed over 2 x 2 pixel window , with stride 2 pixels.\n",
    "    - Fully Connected: 3 layers after a stack of convolution layers.  Third FC layer is softmax layer\n",
    "    - ReLU non-linearity applied to all hidden layers\n",
    "    - Depth of Convolution layer starts from 64 in first layer and then increases by a factor of 2, until it reaches 512\n",
    "    ![](images/vggnet0.png)\n",
    "    - Convolutional layer parameter denoted as: `conv<receptive field size>-<number of channels>`\n",
    "    ![](images/vggnet1.png) \n",
    "- Show Local Response Normalization (AlexNet) normalization does not improve performance on the ImageNet dataset but leads to increase memory consumption and computation time.\n",
    "- Small Filters:\n",
    "    - Used 3 x 3 filters (with stride 1). `Small filters increase effective filter size.`\n",
    "        - Example: Stack two 3 x 3 convolution layers (stride 1). Each neuron sees 3 x 3 region of previous activation map. A neuron on second convolution layer sees 5 x 5 region in input. This means that a stack of two 3 x 3 convolution layer has effective filter size of 5 x 5\n",
    "        ![](images/vggnet2.png)\n",
    "        ![](images/vggnet3.png)\n",
    "    - Stack of three 3 x 3 convolution layers vs a single 7 x 7 convolution layer: 3 non-linear rectification layers instead of one and decrease in number of parameters and computations.\n",
    "     ![](images/vggnet4.png) \n",
    "    - `1 x 1 convolution layer` (the number of input and output channels is the same) is `a way to increase the non-linearity of the decision function without affecting the filter size of the convolution layers.`\n",
    "- Training:\n",
    "    - ImageNet 2012 dataset (1.3 Million images)\n",
    "    - SGD with batch size = 256, momentum = 0.9, learning rate = 0.01 (initially and then decreased by factor of 10 when validation set accuracy stopped improving)\n",
    "    - Training was regularlarized ($\\lambda = 5 \\times 10^{-4}$) by weight decay and dropout regularization for first 2 fully connected layers.\n",
    "    - Weights initialized from a zero mean Gaussian distribution with standard deviation 0.01. Biases initialized with zero.\n",
    "    - Data augmentation: Random horizontal flipping, random RGB color shift and scale jittering.\n",
    "    - Used Caffe tool box to implement CNN\n",
    "- `Demonstrated that convolutional network depth is beneficial for the classification accuracy`\n",
    "\n",
    "---\n",
    "\n",
    "**Object Localization**\n",
    "- Last fully connected layer predicts the bounding box location. A bounding box is represented by a 4-D vector storing its center coordinates, width and height. ConvNet configuration D was used with last layer as bounding box prediction layer.\n",
    "- Euclidean loss which penalizes the deviation of the predicted bounding box parameters from the ground-truth was used during training.\n",
    "- The bounding box prediction is correct if its intersection over union ratio with the ground-truth bounding box is above 0.5\n",
    "![](images/iou.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
