{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems](https://arxiv.org/pdf/1512.01274.pdf)\n",
    "\n",
    "- https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-2-ce761513124e\n",
    "- https://indico.io/blog/getting-started-with-mxnet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NDArray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(2L, 3L)\n",
      "<type 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# NDArray\n",
    "a = mx.nd.array([[1, 2, 3], [4, 5, 6]])\n",
    "print a.size\n",
    "print a.shape\n",
    "print a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.int32'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [1, 2, 3]], dtype=int32), \n",
       " [[1 2 3]\n",
       "  [1 2 3]]\n",
       " <NDArray 2x3 @cpu(0)>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = mx.nd.array([[1, 2, 3], [1, 2, 3]], dtype=np.int32)\n",
    "print b.dtype\n",
    "b.asnumpy(), b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   4.,   9.],\n",
       "       [ 16.,  25.,  36.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise product\n",
    "a = mx.nd.array([[1, 2, 3], [4, 5, 6]])\n",
    "b = a * a\n",
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2L, 3L)\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]]\n",
      "(3L, 2L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14.,  32.],\n",
       "       [ 32.,  77.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product\n",
    "a = mx.nd.array([[1, 2, 3], [4, 5, 6]])\n",
    "print a.shape\n",
    "print a.asnumpy()\n",
    "b = a.T\n",
    "print b.shape\n",
    "c = mx.nd.dot(a, b)\n",
    "c.shape\n",
    "c.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000L, 1000L)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize matrices with different distributions\n",
    "u = mx.nd.uniform(low=0, high=1, shape=(1000, 1000))\n",
    "\n",
    "n = mx.nd.normal(loc=1, scale=2, shape=(1000, 1000))\n",
    "\n",
    "# Dot product\n",
    "d = mx.nd.dot(u, n)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Symbol**\n",
    "\n",
    "Dataflow Programming - A flexible way of defining parallel computation, where data flows through a **graph**. The graph defines the order of operations. Each operation is a *black box*, only its input and output are defined.\n",
    "\n",
    "$$E = (A \\times B) + (C \\times D)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols:  <Symbol A> <Symbol B> <Symbol C> <Symbol D>\n",
      "E:  <Symbol _plus0>\n",
      "E type:  <class 'mxnet.symbol.Symbol'>\n"
     ]
    }
   ],
   "source": [
    "# Define symbols\n",
    "a = mx.sym.Variable(name='A')\n",
    "b = mx.sym.Variable(name='B')\n",
    "c = mx.sym.Variable(name='C')\n",
    "d = mx.sym.Variable(name='D')\n",
    "\n",
    "# Define graph\n",
    "e = (a * b) + (c * d)\n",
    "\n",
    "print 'Symbols: ', a, b, c, d\n",
    "print 'E: ', e\n",
    "print 'E type: ', type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E arguments, i.e. E depends on on variables:  ['A', 'B', 'C', 'D']\n",
      "E inputs:  ['A', 'B', 'C', 'D']\n",
      "E outputs, i.e. Operation that computes E:  ['_plus0_output']\n",
      "E internals:  <Symbol group [A, B, _mul0, C, D, _mul1, _plus0]>\n",
      "E internals outputs:  ['A', 'B', '_mul0_output', 'C', 'D', '_mul1_output', '_plus0_output']\n"
     ]
    }
   ],
   "source": [
    "# E is a symbol and a result of '+' operation\n",
    "print 'E arguments, i.e. E depends on on variables: ', e.list_arguments()\n",
    "print 'E inputs: ', e.list_inputs()\n",
    "print 'E outputs, i.e. Operation that computes E: ', e.list_outputs()\n",
    "print 'E internals: ', e.get_internals()\n",
    "print 'E internals outputs: ', e.get_internals().list_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binding NDArrays and Symbols**\n",
    "\n",
    "Applying computation steps defined with Symbols to data stored in NDArrays requires an operation called **binding**, i.e. assining an NDArray to each input variable of the graph\n",
    " \n",
    "- Data is loaded and prepared using the `imperative` programming model\n",
    "- Computation is performed using the `symbolic` programming model - Allows MXNet to decouple code and data, perform parallel execution and graph optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NDArrays\n",
    "a_data = mx.nd.array([1], dtype=np.int32)\n",
    "b_data = mx.nd.array([2], dtype=np.int32)\n",
    "c_data = mx.nd.array([3], dtype=np.int32)\n",
    "d_data = mx.nd.array([4], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.executor.Executor at 0x7fe0ced6ce50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binding each NDArray to its corresponding Symbol. \n",
    "# NOTE: Need to select the context where execution will take place\n",
    "\n",
    "arguments = {'A': a_data, 'B': b_data, 'C': c_data, 'D': d_data}\n",
    "executor = e.bind(ctx=mx.cpu(device_id=0), args=arguments)\n",
    "executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[14]\n",
      "<NDArray 1 @cpu(0)>]\n",
      "\n",
      "[14]\n",
      "<NDArray 1 @cpu(0)>\n",
      "[14]\n"
     ]
    }
   ],
   "source": [
    "# Let input data flow through the graph\n",
    "e_data = executor.forward()\n",
    "print e_data\n",
    "print e_data[0]\n",
    "print e_data[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[[ 0.25428662  0.2716822   0.08855453 ...,  0.17513204  0.12643263\n",
      "   0.24611941]\n",
      " [ 0.43185544  0.93409884  1.13012767 ...,  1.26165771  0.93693149\n",
      "   0.92390227]\n",
      " [ 0.34301594  0.10574408  0.47203985 ...,  0.06712524  0.86225599\n",
      "   0.38010356]\n",
      " ..., \n",
      " [ 0.7397536   0.76276726  0.5228703  ...,  0.40895808  1.04495525\n",
      "   1.34238076]\n",
      " [ 0.09233697  1.00399196  0.06909392 ...,  0.69651967  0.70354009\n",
      "   0.40740401]\n",
      " [ 0.39363438  0.85467219  0.08330497 ...,  0.17517376  0.36264491\n",
      "   0.81301337]]\n",
      "<NDArray 1000x1000 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "# Apply same graph to larger matrices: Just need to define inputs (binding and computation are identical)\n",
    "a_data = mx.nd.uniform(low=0, high=1, shape=(1000, 1000))\n",
    "b_data = mx.nd.uniform(low=0, high=1, shape=(1000, 1000))\n",
    "c_data = mx.nd.uniform(low=0, high=1, shape=(1000, 1000))\n",
    "d_data = mx.nd.uniform(low=0, high=1, shape=(1000, 1000))\n",
    "\n",
    "# Bind data to symbol\n",
    "arguments = {'A': a_data, 'B': b_data, 'C': c_data, 'D': d_data}\n",
    "executor = e.bind(ctx=mx.cpu(device_id=0), args=arguments)\n",
    "\n",
    "# Let input data flow through the graph\n",
    "e_data = executor.forward()\n",
    "print e_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module**\n",
    "\n",
    "- Synthetic data\n",
    "    - 1000 samples\n",
    "    - 100 features (each represented by a float value between 0 and 1)\n",
    "    - 10 categories\n",
    "    - Train/Test split: 80/20\n",
    "    - Batch size: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X shape: ', (1000L, 100L))\n",
      "('Y shape: ', (1000L,))\n"
     ]
    }
   ],
   "source": [
    "# Generate the data set\n",
    "sample_count = 1000\n",
    "train_count = 800\n",
    "val_count = sample_count - train_count\n",
    "\n",
    "feature_count = 100\n",
    "category_count = 10\n",
    "batch_size = 10\n",
    "\n",
    "X = mx.nd.uniform(low=0, high=1, shape=(sample_count, feature_count))\n",
    "print('X shape: ', X.shape)\n",
    "\n",
    "Y = mx.nd.empty(shape=(sample_count,))\n",
    "for i in range(0, sample_count-1):\n",
    "    Y[i] = np.random.randint(0, category_count)\n",
    "    \n",
    "print('Y shape: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set (data is random so no need to shuffle)\n",
    "X_train = mx.nd.slice(data=X, begin=(0, 0), end=(train_count, feature_count-1))\n",
    "X_val = mx.nd.slice(data=X, begin=(train_count, 0), end=(sample_count, feature_count-1))\n",
    "\n",
    "Y_train = Y[0:train_count]\n",
    "Y_val = Y[train_count:sample_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the network\n",
    "data = mx.sym.Variable(name='data')\n",
    "fc1 = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=64)\n",
    "relu1 = mx.sym.Activation(data=fc1, name='relu1', act_type='relu')\n",
    "fc2 = mx.sym.FullyConnected(data=relu1, name='fc2', num_hidden=category_count)\n",
    "out = mx.sym.Softmax(data=fc2, name='softmax')\n",
    "\n",
    "# Create a module\n",
    "module = mx.mod.Module(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building the data iterator\n",
    "train_iter = mx.io.NDArrayIter(data=X_train, label=Y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "/home/ankoor/DeepRadiology/mxnet-stable/python/mxnet/module/base_module.py:464: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Train-accuracy=0.092500\n",
      "INFO:root:Epoch[0] Time cost=0.202\n",
      "INFO:root:Epoch[1] Train-accuracy=0.128750\n",
      "INFO:root:Epoch[1] Time cost=0.166\n",
      "INFO:root:Epoch[2] Train-accuracy=0.153750\n",
      "INFO:root:Epoch[2] Time cost=0.129\n",
      "INFO:root:Epoch[3] Train-accuracy=0.175000\n",
      "INFO:root:Epoch[3] Time cost=0.115\n",
      "INFO:root:Epoch[4] Train-accuracy=0.200000\n",
      "INFO:root:Epoch[4] Time cost=0.107\n",
      "INFO:root:Epoch[5] Train-accuracy=0.220000\n",
      "INFO:root:Epoch[5] Time cost=0.240\n",
      "INFO:root:Epoch[6] Train-accuracy=0.241250\n",
      "INFO:root:Epoch[6] Time cost=0.169\n",
      "INFO:root:Epoch[7] Train-accuracy=0.251250\n",
      "INFO:root:Epoch[7] Time cost=0.100\n",
      "INFO:root:Epoch[8] Train-accuracy=0.280000\n",
      "INFO:root:Epoch[8] Time cost=0.088\n",
      "INFO:root:Epoch[9] Train-accuracy=0.293750\n",
      "INFO:root:Epoch[9] Time cost=0.071\n",
      "INFO:root:Epoch[10] Train-accuracy=0.310000\n",
      "INFO:root:Epoch[10] Time cost=0.169\n",
      "INFO:root:Epoch[11] Train-accuracy=0.336250\n",
      "INFO:root:Epoch[11] Time cost=0.115\n",
      "INFO:root:Epoch[12] Train-accuracy=0.351250\n",
      "INFO:root:Epoch[12] Time cost=0.088\n",
      "INFO:root:Epoch[13] Train-accuracy=0.371250\n",
      "INFO:root:Epoch[13] Time cost=0.077\n",
      "INFO:root:Epoch[14] Train-accuracy=0.393750\n",
      "INFO:root:Epoch[14] Time cost=0.096\n",
      "INFO:root:Epoch[15] Train-accuracy=0.418750\n",
      "INFO:root:Epoch[15] Time cost=0.079\n",
      "INFO:root:Epoch[16] Train-accuracy=0.428750\n",
      "INFO:root:Epoch[16] Time cost=0.086\n",
      "INFO:root:Epoch[17] Train-accuracy=0.455000\n",
      "INFO:root:Epoch[17] Time cost=0.132\n",
      "INFO:root:Epoch[18] Train-accuracy=0.472500\n",
      "INFO:root:Epoch[18] Time cost=0.056\n",
      "INFO:root:Epoch[19] Train-accuracy=0.498750\n",
      "INFO:root:Epoch[19] Time cost=0.071\n",
      "INFO:root:Epoch[20] Train-accuracy=0.511250\n",
      "INFO:root:Epoch[20] Time cost=0.121\n",
      "INFO:root:Epoch[21] Train-accuracy=0.520000\n",
      "INFO:root:Epoch[21] Time cost=0.092\n",
      "INFO:root:Epoch[22] Train-accuracy=0.551250\n",
      "INFO:root:Epoch[22] Time cost=0.098\n",
      "INFO:root:Epoch[23] Train-accuracy=0.583750\n",
      "INFO:root:Epoch[23] Time cost=0.076\n",
      "INFO:root:Epoch[24] Train-accuracy=0.597500\n",
      "INFO:root:Epoch[24] Time cost=0.077\n",
      "INFO:root:Epoch[25] Train-accuracy=0.618750\n",
      "INFO:root:Epoch[25] Time cost=0.067\n",
      "INFO:root:Epoch[26] Train-accuracy=0.643750\n",
      "INFO:root:Epoch[26] Time cost=0.117\n",
      "INFO:root:Epoch[27] Train-accuracy=0.665000\n",
      "INFO:root:Epoch[27] Time cost=0.209\n",
      "INFO:root:Epoch[28] Train-accuracy=0.691250\n",
      "INFO:root:Epoch[28] Time cost=0.110\n",
      "INFO:root:Epoch[29] Train-accuracy=0.687500\n",
      "INFO:root:Epoch[29] Time cost=0.082\n",
      "INFO:root:Epoch[30] Train-accuracy=0.723750\n",
      "INFO:root:Epoch[30] Time cost=0.185\n",
      "INFO:root:Epoch[31] Train-accuracy=0.738750\n",
      "INFO:root:Epoch[31] Time cost=0.067\n",
      "INFO:root:Epoch[32] Train-accuracy=0.773750\n",
      "INFO:root:Epoch[32] Time cost=0.067\n",
      "INFO:root:Epoch[33] Train-accuracy=0.797500\n",
      "INFO:root:Epoch[33] Time cost=0.345\n",
      "INFO:root:Epoch[34] Train-accuracy=0.818750\n",
      "INFO:root:Epoch[34] Time cost=0.131\n",
      "INFO:root:Epoch[35] Train-accuracy=0.841250\n",
      "INFO:root:Epoch[35] Time cost=0.074\n",
      "INFO:root:Epoch[36] Train-accuracy=0.855000\n",
      "INFO:root:Epoch[36] Time cost=0.172\n",
      "INFO:root:Epoch[37] Train-accuracy=0.881250\n",
      "INFO:root:Epoch[37] Time cost=0.076\n",
      "INFO:root:Epoch[38] Train-accuracy=0.906250\n",
      "INFO:root:Epoch[38] Time cost=0.132\n",
      "INFO:root:Epoch[39] Train-accuracy=0.925000\n",
      "INFO:root:Epoch[39] Time cost=0.101\n",
      "INFO:root:Epoch[40] Train-accuracy=0.927500\n",
      "INFO:root:Epoch[40] Time cost=0.074\n",
      "INFO:root:Epoch[41] Train-accuracy=0.946250\n",
      "INFO:root:Epoch[41] Time cost=0.144\n",
      "INFO:root:Epoch[42] Train-accuracy=0.948750\n",
      "INFO:root:Epoch[42] Time cost=0.215\n",
      "INFO:root:Epoch[43] Train-accuracy=0.960000\n",
      "INFO:root:Epoch[43] Time cost=0.151\n",
      "INFO:root:Epoch[44] Train-accuracy=0.962500\n",
      "INFO:root:Epoch[44] Time cost=0.080\n",
      "INFO:root:Epoch[45] Train-accuracy=0.962500\n",
      "INFO:root:Epoch[45] Time cost=0.088\n",
      "INFO:root:Epoch[46] Train-accuracy=0.967500\n",
      "INFO:root:Epoch[46] Time cost=0.166\n",
      "INFO:root:Epoch[47] Train-accuracy=0.975000\n",
      "INFO:root:Epoch[47] Time cost=0.099\n",
      "INFO:root:Epoch[48] Train-accuracy=0.978750\n",
      "INFO:root:Epoch[48] Time cost=0.143\n",
      "INFO:root:Epoch[49] Train-accuracy=0.988750\n",
      "INFO:root:Epoch[49] Time cost=0.285\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "\n",
    "# Bind the input symbol to data\n",
    "module.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "\n",
    "# Initialize the neuron weights\n",
    "module.init_params(initializer=mx.init.Xavier(magnitude=2.0))\n",
    "\n",
    "# Define optimization parameters\n",
    "module.init_optimizer(optimizer='sgd', optimizer_params=(('learning_rate', 0.1), ))\n",
    "\n",
    "# Train\n",
    "module.fit(train_data=train_iter, num_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.095\n"
     ]
    }
   ],
   "source": [
    "# Validating the model\n",
    "\n",
    "# Build val iterator\n",
    "val_iter = mx.io.NDArrayIter(data=X_val, label=Y_val, batch_size=batch_size)\n",
    "\n",
    "# Validation accuracy\n",
    "pred_count = val_count\n",
    "correct_preds = total_correct_preds = 0\n",
    "\n",
    "for preds, i_batch, batch in module.iter_predict(val_iter):\n",
    "    label = batch.label[0].asnumpy().astype(int)\n",
    "    pred_label = preds[0].asnumpy().argmax(axis=1)\n",
    "    correct_preds = np.sum(pred_label==label)\n",
    "    total_correct_preds += correct_preds\n",
    "    \n",
    "print('Validation accuracy: {:2.3f}'.format(total_correct_preds/float(pred_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
